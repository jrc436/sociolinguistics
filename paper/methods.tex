\section{Methods}
\subsection{Data Preparation}
We first gathered a list of comments by checking if they contained any keywords associated with that conflict. The goal of this list was to be broad enough to capture any given comment while also ensuring that comments would be a positive identification of the topic. It is a near guarantee that some comments that were collected would not actually pertain to the given conflict. However, with enough data, we hoped to filter out the noise. Our answer to this is to use enough data to filter out most of the noise. The biggest source of comments was /r/worldnews, with many of the others coming from similar subreddits, implying that most of the comments were likely about the intended topic. The comments came from over a thousand subreddits; some of these could be falsely identified to be relevant, while some of them could be off topic. 

As discussed earlier, we ran sentiment analysis on the comments we collected. Interestingly, there were many more negative comments than positive comments. It is possible that this is due to the subject matter; in general, pity and sadness might be more common responses to tragedy than optimism and hope. It could also be due to the nature of the corpus itself: young people on pseudononymous Internet communities could be more negative than average. Nonetheless, we separated the negative and positive comments and pruned the neutral ones.

Lastly, we must define what it means to be acceptable. In Reddit, this is  simply whether a comment has been upvoted or downvoted more. All comments start with a score of one; the idea is that you always approve of your own comment. As comments with a score of one thus contain no useful information about how the community perceived them, they were excluded. 

As Reddit manipulates how probable it is for people to see a post, we did not consider the actual number of upvotes or downvotes received to be useful information. We thus coded anything upvoted past one as not unacceptable, and anything downvoted below one as unacceptable.

Posts that were deemed controversial by Reddit were vanishingly rare, making up less than 2\% of the filtered comments. Thus, people clearly tend to downvote comments that were already downvoted and upvote comments that were already upvoted (or to take no action at all). Therefore, a binary value of approval seemed more appropriate than any other choice.

Our two filters resulted in 781 positive comments and 14289 negative comments. The substantial difference in sentiment furthered our desire to split the analysis. Comparing these two models could help us determine if there are different circumstances when expressing different types of sentiment is more acceptable. Due to the overwhelming number of negative comments (over 95\%), it is difficult to interpret the negative sentiment as much more than the norm. If this is the case, then our results, instead of reflecting when negative sentiment would be acceptable, would reflect when posters are more likely to post something that is unacceptable. We'll discuss what that might mean later.

\subsection{Model}
We use a Logistic Linear Mixed Effects Model (GLMM) to attempt to explain which sentiments were acceptable as determined by the conflict.

\subsubsection{Response}
Every comment is coded as either unacceptable (1) or acceptable (0). This means that for some feature of a conflict that a comment is about, positive $\beta$ implies that comment is more likely to be disapproved of. Conversely, negative $\beta$ implies that comment is less likely to be disapproved of. 

\subsubsection{Fixed Effects}
A summary of our fixed effects is given by our research questions.

\subsubsection{Random Effects}
We grouped intercepts by Author and by Subreddit. As Reddit is pseudononymous, some authors may have a reputation for making consistently good or bad posts, and different communities may have different standards for acceptability.